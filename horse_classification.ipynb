{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbCb-ME9BVCj"
   },
   "source": [
    "# **Build a Dataset Class for Horse Breeds**\n",
    "\n",
    "https://www.kaggle.com/datasets/olgabelitskaya/horse-breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T12:12:58.971268Z",
     "iopub.status.busy": "2025-02-02T12:12:58.970830Z",
     "iopub.status.idle": "2025-02-02T12:12:59.145241Z",
     "shell.execute_reply": "2025-02-02T12:12:59.144101Z",
     "shell.execute_reply.started": "2025-02-02T12:12:58.971237Z"
    },
    "id": "ykaIVwjGBVCk",
    "outputId": "d2317efe-1f6f-45aa-c21c-d0b700acf049",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /root/.cache/kagglehub/datasets/olgabelitskaya/horse-breeds/versions/27\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"olgabelitskaya/horse-breeds\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "416gARb6Kx5e"
   },
   "source": [
    "### Split the data into train val, and test set (starified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = []\n",
    "for ext in ('/**/*.jpg', '/**/*.jpeg', '/**/*.JPG', '/**/*.png'):\n",
    "    all_images.extend(glob.glob(path + ext, recursive=True))\n",
    "\n",
    "data = []\n",
    "\n",
    "for img_path in all_images:\n",
    "    breed = os.path.basename(os.path.dirname(img_path))\n",
    "    data.append((img_path, breed))\n",
    "\n",
    "df = pd.DataFrame(data, columns=['filepath', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_idx = {label: i for i, label in enumerate(df['label'].unique())}\n",
    "df['label_idx'] = df['label'].map(label_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 670\n",
      "Train size: 536 | Val size: 67 | Test size: 67\n"
     ]
    }
   ],
   "source": [
    "train_df, temp_df = train_test_split(\n",
    "    df, test_size=0.20, stratify=df['label_idx'], random_state=42\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, test_size=0.50, stratify=temp_df['label_idx'], random_state=42\n",
    ")\n",
    "print(f\"Total images: {len(df)}\")\n",
    "print(f\"Train size: {len(train_df)} | Val size: {len(val_df)} | Test size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PeUp4wJeCntl"
   },
   "source": [
    "### Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class HorseBreedDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx]['filepath']\n",
    "        label = self.dataframe.iloc[idx]['label_idx']\n",
    "        \n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VwT-AGQCmCL"
   },
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def calculate_stats(dataset):\n",
    "    \n",
    "    loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "    \n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "    total_images = 0\n",
    "    \n",
    "    for images, _ in loader:\n",
    "        \n",
    "        batch_samples = images.size(0) \n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        \n",
    "\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "        total_images += batch_samples\n",
    "\n",
    "    \n",
    "    mean /= total_images\n",
    "    std /= total_images\n",
    "    \n",
    "    return mean, std\n",
    "\n",
    "\n",
    "temp_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "temp_dataset = HorseBreedDataset(df, transform=temp_transforms)\n",
    "mean, std = calculate_stats(temp_dataset)\n",
    "\n",
    "print(f\"Calculated Mean: {mean}\")\n",
    "print(f\"Calculated Std: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f77ElydmCrQZ"
   },
   "source": [
    "### Create Dataloader objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nr0VNAPiCi30"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_set = HorseBreedDataset(train_df, transform=train_transforms)\n",
    "val_set = HorseBreedDataset(val_df, transform=val_test_transforms)\n",
    "test_set = HorseBreedDataset(test_df, transform=val_test_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwALCkxODkjC"
   },
   "source": [
    "#### Display some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lie9vP8wDla3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build one_epoch_training function loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build one_epoch_validation function loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all to train the model\n",
    "it should Save the best model and track train and val loss and accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test the model on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show some predictions with the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the results\n",
    "Is the model overfitting/underfitting?\n",
    "Plot the training and validation loss/accuracy curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNqIJGCx2F6e6EZLgWIWJp6",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
